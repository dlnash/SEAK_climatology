{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8b9efb-0fa1-4d7e-a30a-6c5adf81dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c10b252-fe7c-4f60-a6c4-340cf1d7ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'      # project data -- read only\n",
    "path_to_work = '/cw3e/mead/projects/cwp140/scratch/dnash/data/preprocessed/SEAK-WRF-precip/'\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a433fc7-c2ee-4270-8e64-126b201e5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to pull precip time series from data\n",
    "## choose which option\n",
    "# (a) select the grid cell closest to each of the communities\n",
    "# (b) select the 9 closest grid cells to each of the communities - take maximum value\n",
    "# (c) select the 25 closest grid cells to each of the communities- take maximum value\n",
    "option = 'a'\n",
    "\n",
    "### choose which temporal resolution for the precipitation data (hourly or daily)\n",
    "temporal_res = 'hourly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3e3633-8749-4a8b-8e7e-8ec6d10b1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: make a yaml dict\n",
    "ext1 = [-141., -130., 54., 61.] # extent of SEAK \n",
    "\n",
    "## six communities\n",
    "# -135.4519\t58.1122, Hoonah (PAOH) \n",
    "# -135.3277\t59.4538, Skagway (PAGY)\n",
    "# -135.8894, 59.3988, Klukwan\n",
    "# -139.671\t59.5121, Yakutat (PAYA)\n",
    "# -133.1358, 55.4769, Craig\n",
    "# -132.4009, 55.5400, Kasaan\n",
    "\n",
    "xs = [-135.4519, -135.3277, -135.8894, -139.671, -133.1358, -132.4009]\n",
    "ys = [58.1122, 59.4538, 59.3988, 59.5121, 55.4769, 55.5400]\n",
    "lbl1 = ['Hoonah', 'Skagway', 'Klukwan', 'Yakutat', 'Craig', 'Kasaan']\n",
    "lbl_align = ['center', 'left', 'right', 'center', 'right', 'center'] # where the labels go\n",
    "\n",
    "## closest station\n",
    "# -135.4519\t58.1122, Hoonah (PAOH) \n",
    "# -135.3277\t59.4538, Skagway (PAGY)\n",
    "# -135.5117\t59.2429, Haines (PAHN)\n",
    "# -139.671\t59.5121, Yakutat (PAYA)\n",
    "# -133.076\t55.5792, Klawock (PAKW)\n",
    "# -131.7117\t55.3567, Ketchikan (PAKT)\n",
    "xs2 = [-135.4519, -135.3277, -135.5117, -139.671, -133.076, -131.7117]\n",
    "ys2 = [58.1122, 59.4538, 59.2429, 59.5121, 55.5792, 55.3567]\n",
    "lbl2 = ['PAOH', 'PAGY', 'PAHN', 'PAYA', 'PAKW', 'PAKT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee899c-c7f5-43ee-ae65-f76c0bd3c804",
   "metadata": {},
   "source": [
    "### Import preprocessed SEAK-WRF precip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5e9ae2-2e5b-4bb6-ac5a-1cc9631f6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_pattern = path_to_work + 'WRFDS_PCPT_*.nc'\n",
    "wrf = xr.open_mfdataset(fname_pattern, combine='by_coords')\n",
    "\n",
    "if temporal_res == 'hourly':\n",
    "    wrf = wrf\n",
    "elif temporal_res == 'daily':\n",
    "    wrf = wrf.resample(time=\"1D\").sum('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dd5b5-0e4a-4d78-b0dd-72c5ee93a1cf",
   "metadata": {},
   "source": [
    "## Generate precipitation time series for each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6802d823-a19f-4a2e-bca5-e82198bf29fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 s, sys: 1min 47s, total: 1min 50s\n",
      "Wall time: 19min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diff_lat = wrf.lat.values[2] - wrf.lat.values[1]\n",
    "diff_lon = wrf.lon.values[2] - wrf.lon.values[1]\n",
    "df_lst2 = []\n",
    "row_lbl2 = []\n",
    "for i, (slon, slat) in enumerate(zip(xs, ys)):\n",
    "    \n",
    "    if option == 'a':\n",
    "        ## select nearest grid cell to station\n",
    "        ds = wrf.sel(lat=slat, lon=slon, method=\"nearest\")\n",
    "    elif option == 'b':\n",
    "        scale = 1.5 ## \"nearest neighbor\" grid cells\n",
    "        ds = wrf.sel(lat=slice(slat-diff_lat*scale, slat+diff_lat*scale), lon=slice(slon-diff_lon*scale, slon+diff_lon*scale))\n",
    "        ds = ds.max(['lat', 'lon'])\n",
    "    elif option == 'c': \n",
    "        scale = 2.5 ## \"nearest neighbor\" grid cells plus buffer\n",
    "        ds = wrf.sel(lat=slice(slat-diff_lat*scale, slat+diff_lat*scale), lon=slice(slon-diff_lon*scale, slon+diff_lon*scale))\n",
    "        ds = ds.max(['lat', 'lon'])\n",
    "    \n",
    "    df = ds.prec.to_dataframe()\n",
    "    df = df.rename(columns={\"prec\": lbl1[i]}) # rename precip column to the name of the community\n",
    "    df_lst2.append(df)\n",
    "    \n",
    "    # make nice labels for plot\n",
    "    lbl = u\"{:.2f}\\N{DEGREE SIGN}N, {:.2f}\\N{DEGREE SIGN}W\".format(slat, slon*-1)\n",
    "    row_lbl2.append(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c64455-2dd8-4b6b-83a6-15145e3e0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = []\n",
    "# for i, df in enumerate(df_lst2):\n",
    "#     df = df.drop(['lat', 'lon'], axis=1)\n",
    "#     df_new.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e8ba417-bf69-49ac-864d-5b675498c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11665/1949257098.py:2: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lat_x', 'lon_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merged = reduce(lambda x, y: pd.merge(x, y, on = 'time'), df_lst2)\n",
      "/tmp/ipykernel_11665/1949257098.py:2: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lat_x', 'lon_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merged = reduce(lambda x, y: pd.merge(x, y, on = 'time'), df_lst2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hoonah</th>\n",
       "      <th>Skagway</th>\n",
       "      <th>Klukwan</th>\n",
       "      <th>Yakutat</th>\n",
       "      <th>Craig</th>\n",
       "      <th>Kasaan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01 00:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-01 01:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-01 02:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-01 03:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-01 04:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 19:00:00</th>\n",
       "      <td>1.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.421875</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 20:00:00</th>\n",
       "      <td>1.039062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.906250</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>2.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:00:00</th>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>2.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:00:00</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.054688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Hoonah  Skagway   Klukwan   Yakutat    Craig    Kasaan\n",
       "time                                                                         \n",
       "1980-01-01 00:00:00  0.000000      0.0  0.000000  0.000000  0.00000  0.000000\n",
       "1980-01-01 01:00:00  0.000000      0.0  0.000000  0.000000  0.00000  0.000000\n",
       "1980-01-01 02:00:00  0.000000      0.0  0.000000  0.000000  0.00000  0.000000\n",
       "1980-01-01 03:00:00  0.000000      0.0  0.000000  0.000000  0.00000  0.000000\n",
       "1980-01-01 04:00:00  0.000000      0.0  0.000000  0.000000  0.00000  0.000000\n",
       "...                       ...      ...       ...       ...      ...       ...\n",
       "2019-12-31 19:00:00  1.843750      0.0  0.000000  1.421875  0.00000  0.000000\n",
       "2019-12-31 20:00:00  1.039062      0.0  0.000000  2.906250  0.43750  2.289062\n",
       "2019-12-31 21:00:00  0.757812      0.0  0.000000  5.812500  0.28125  2.781250\n",
       "2019-12-31 22:00:00  0.468750      0.0  0.332031  2.593750  0.00000  1.171875\n",
       "2019-12-31 23:00:00  0.000000      0.0  0.015625  2.500000  0.00000  0.054688\n",
       "\n",
       "[350400 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge all dfs to one\n",
    "df_merged = reduce(lambda x, y: pd.merge(x, y, on = 'time'), df_lst2)\n",
    "## hack for weird behavior for daily df option a\n",
    "if (option == 'a'):\n",
    "    df_merged = df_merged.drop(['lat_x', 'lat_y', 'lon_x', 'lon_y'], axis=1)\n",
    "    \n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b9d7c5-dddd-4526-b076-72c4ab5570ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to csv file\n",
    "df_merged.to_csv(path_to_out + 'SEAK_precip_max_{0}_{1}.csv'.format(option, temporal_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808cce1f-9ffe-4dd5-b03d-accdd5c46518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEAK-clim)",
   "language": "python",
   "name": "seak-clim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
