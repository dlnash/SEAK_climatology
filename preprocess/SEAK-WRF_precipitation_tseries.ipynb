{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8b9efb-0fa1-4d7e-a30a-6c5adf81dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from functools import reduce\n",
    "import xoak\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c10b252-fe7c-4f60-a6c4-340cf1d7ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'      # project data -- read only\n",
    "path_to_work = '/cw3e/mead/projects/cwp140/scratch/dnash/data/preprocessed/'\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a433fc7-c2ee-4270-8e64-126b201e5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to pull precip time series from data\n",
    "## choose which option\n",
    "# (a) select the grid cell closest to each of the communities\n",
    "# (b) select the 9 closest grid cells to each of the communities - take maximum value\n",
    "# (c) select the 25 closest grid cells to each of the communities- take maximum value\n",
    "option = 'a'\n",
    "\n",
    "### choose which temporal resolution for the precipitation data (hourly or daily)\n",
    "temporal_res = 'daily'\n",
    "\n",
    "### variable name (PCPT, T2, UV)\n",
    "varname = 'UV'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3e3633-8749-4a8b-8e7e-8ec6d10b1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: make a yaml dict\n",
    "ext1 = [-141., -130., 54., 61.] # extent of SEAK \n",
    "\n",
    "## six communities\n",
    "# -135.4519\t58.1122, Hoonah (PAOH) \n",
    "# -135.3277\t59.4538, Skagway (PAGY)\n",
    "# -135.8894, 59.3988, Klukwan\n",
    "# -139.671\t59.5121, Yakutat (PAYA)\n",
    "# -133.1358, 55.4769, Craig\n",
    "# -132.4009, 55.5400, Kasaan\n",
    "\n",
    "xs = [-135.4519, -135.3277, -135.8894, -139.671, -133.1358, -132.4009]\n",
    "ys = [58.1122, 59.4538, 59.3988, 59.5121, 55.4769, 55.5400]\n",
    "lbl1 = ['Hoonah', 'Skagway', 'Klukwan', 'Yakutat', 'Craig', 'Kasaan']\n",
    "lbl_align = ['center', 'left', 'right', 'center', 'right', 'center'] # where the labels go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee899c-c7f5-43ee-ae65-f76c0bd3c804",
   "metadata": {},
   "source": [
    "### Import preprocessed SEAK-WRF precip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5e9ae2-2e5b-4bb6-ac5a-1cc9631f6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /cw3e/mead/projects/cwp140/scratch/dnash/miniconda3/envs/SEAK-clim/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "fname_pattern = path_to_work + 'SEAK-WRF-{0}/WRFDS_{0}_*.nc'.format(varname)\n",
    "wrf = xr.open_mfdataset(fname_pattern, combine='by_coords')\n",
    "        \n",
    "if varname == 'UV':\n",
    "    wrf = wrf.sel(lev='1000')\n",
    "      \n",
    "if (temporal_res == 'daily') & (varname == 'PCPT'):\n",
    "    wrf = wrf.resample(time=\"1D\").sum('time')\n",
    "\n",
    "elif (temporal_res == 'daily') & (varname != 'PCPT'):\n",
    "    wrf = wrf.resample(time=\"1D\").mean('time')\n",
    "\n",
    "elif (temporal_res == 'hourly'):\n",
    "    wrf = wrf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dd5b5-0e4a-4d78-b0dd-72c5ee93a1cf",
   "metadata": {},
   "source": [
    "## Generate precipitation time series for each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6802d823-a19f-4a2e-bca5-e82198bf29fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 38s, sys: 40min 54s, total: 1h 12min 33s\n",
      "Wall time: 2h 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# diff_lat = wrf.lat.values[2] - wrf.lat.values[1]\n",
    "# diff_lon = wrf.lon.values[2] - wrf.lon.values[1]\n",
    "df_lst2 = []\n",
    "row_lbl2 = []\n",
    "for i, (slon, slat) in enumerate(zip(xs, ys)):\n",
    "    \n",
    "    if option == 'a':\n",
    "        ## select nearest grid cell to station\n",
    "        points = xr.Dataset({\"lat\": slat, \"lon\": slon})\n",
    "        wrf.xoak.set_index([\"lat\", \"lon\"], \"sklearn_geo_balltree\")\n",
    "        ds = wrf.xoak.sel(lat=points.lat, lon=points.lon)\n",
    "        \n",
    "        if varname == 'UV':\n",
    "            ## calculate UV direction\n",
    "            uvec = units.Quantity(ds['U'].values, \"m/s\")\n",
    "            vvec = units.Quantity(ds['V'].values, \"m/s\")\n",
    "            uvdir = mpcalc.wind_direction(uvec, vvec)\n",
    "            ds = ds.assign(UV=lambda ds: uvdir)\n",
    "\n",
    "    \n",
    "    df = ds[varname].to_dataframe()\n",
    "    df['time'] = ds.time.values\n",
    "    df = df.rename(columns={varname: lbl1[i]}) # rename from varname to the name of the community\n",
    "    df_lst2.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8ba417-bf69-49ac-864d-5b675498c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32441/59994185.py:2: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_x', 'lev_x', 'lat_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merged = reduce(lambda x, y: pd.merge(x, y, on = 'time'), df_lst2)\n",
      "/tmp/ipykernel_32441/59994185.py:2: FutureWarning: Passing 'suffixes' which cause duplicate columns {'lon_x', 'lev_x', 'lat_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merged = reduce(lambda x, y: pd.merge(x, y, on = 'time'), df_lst2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hoonah</th>\n",
       "      <th>time</th>\n",
       "      <th>Skagway</th>\n",
       "      <th>Klukwan</th>\n",
       "      <th>Yakutat</th>\n",
       "      <th>Craig</th>\n",
       "      <th>Kasaan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.499893</td>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>327.242584</td>\n",
       "      <td>228.140335</td>\n",
       "      <td>59.335022</td>\n",
       "      <td>115.466476</td>\n",
       "      <td>100.156219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.698051</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>337.506927</td>\n",
       "      <td>234.494370</td>\n",
       "      <td>59.823841</td>\n",
       "      <td>114.195038</td>\n",
       "      <td>99.809120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.430416</td>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>306.871979</td>\n",
       "      <td>231.602646</td>\n",
       "      <td>71.329239</td>\n",
       "      <td>175.440323</td>\n",
       "      <td>42.634338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.557716</td>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>280.968018</td>\n",
       "      <td>247.927551</td>\n",
       "      <td>62.434628</td>\n",
       "      <td>332.557251</td>\n",
       "      <td>334.234741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.936264</td>\n",
       "      <td>1980-01-05</td>\n",
       "      <td>299.025696</td>\n",
       "      <td>185.715652</td>\n",
       "      <td>85.019539</td>\n",
       "      <td>18.865433</td>\n",
       "      <td>355.335297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>168.980515</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>353.132355</td>\n",
       "      <td>43.484665</td>\n",
       "      <td>180.245224</td>\n",
       "      <td>180.679565</td>\n",
       "      <td>139.058334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>127.320236</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>336.062927</td>\n",
       "      <td>8.320633</td>\n",
       "      <td>121.337975</td>\n",
       "      <td>155.216583</td>\n",
       "      <td>135.899094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>112.846909</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>344.921143</td>\n",
       "      <td>30.850540</td>\n",
       "      <td>127.953171</td>\n",
       "      <td>135.850113</td>\n",
       "      <td>121.143997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>79.639374</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>342.101349</td>\n",
       "      <td>12.699074</td>\n",
       "      <td>107.265442</td>\n",
       "      <td>153.996002</td>\n",
       "      <td>131.886124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14609</th>\n",
       "      <td>187.195801</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>342.763336</td>\n",
       "      <td>42.073231</td>\n",
       "      <td>106.300339</td>\n",
       "      <td>162.021362</td>\n",
       "      <td>135.860703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14610 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Hoonah       time     Skagway     Klukwan     Yakutat       Craig  \\\n",
       "0       16.499893 1980-01-01  327.242584  228.140335   59.335022  115.466476   \n",
       "1       65.698051 1980-01-02  337.506927  234.494370   59.823841  114.195038   \n",
       "2       53.430416 1980-01-03  306.871979  231.602646   71.329239  175.440323   \n",
       "3       22.557716 1980-01-04  280.968018  247.927551   62.434628  332.557251   \n",
       "4       85.936264 1980-01-05  299.025696  185.715652   85.019539   18.865433   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "14605  168.980515 2019-12-27  353.132355   43.484665  180.245224  180.679565   \n",
       "14606  127.320236 2019-12-28  336.062927    8.320633  121.337975  155.216583   \n",
       "14607  112.846909 2019-12-29  344.921143   30.850540  127.953171  135.850113   \n",
       "14608   79.639374 2019-12-30  342.101349   12.699074  107.265442  153.996002   \n",
       "14609  187.195801 2019-12-31  342.763336   42.073231  106.300339  162.021362   \n",
       "\n",
       "           Kasaan  \n",
       "0      100.156219  \n",
       "1       99.809120  \n",
       "2       42.634338  \n",
       "3      334.234741  \n",
       "4      355.335297  \n",
       "...           ...  \n",
       "14605  139.058334  \n",
       "14606  135.899094  \n",
       "14607  121.143997  \n",
       "14608  131.886124  \n",
       "14609  135.860703  \n",
       "\n",
       "[14610 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge all dfs to one\n",
    "df_merged = reduce(lambda x, y: pd.merge(x, y, on = 'time'), df_lst2)\n",
    "## hack for weird behavior for daily df option a\n",
    "if (option == 'a'):\n",
    "    df_merged = df_merged.drop(['lat_x', 'lat_y', 'lon_x', 'lon_y', 'lev_x', 'lev_y'], axis=1)\n",
    "    \n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08b9d7c5-dddd-4526-b076-72c4ab5570ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to csv file\n",
    "df_merged.to_csv(path_to_out + 'SEAK_{0}_{1}_{2}.csv'.format(varname, option, temporal_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808cce1f-9ffe-4dd5-b03d-accdd5c46518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEAK-clim)",
   "language": "python",
   "name": "seak-clim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
